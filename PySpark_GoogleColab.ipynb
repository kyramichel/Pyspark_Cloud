{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtfQrkDITK0E"
      },
      "source": [
        "# **How 2 Run PySpark in Jupiter environment using Google Colab**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0N91woG1f7x"
      },
      "source": [
        "\n",
        "### Spark \n",
        "\n",
        "-  an open-source software for fast big data processing\n",
        "\n",
        "### Jupyter notebook \n",
        "\n",
        "a  powerful development tool:\n",
        "\n",
        "- ability to interact directly with the OS from within notebook\n",
        "\n",
        "- debugging without access to a debugger\n",
        "\n",
        "-  execute programming, scripting and markup langauges such as Python, HTML, LaTeX\n",
        "\n",
        "### Google Colab \n",
        "\n",
        " - a free cloud service based on Jupyter Notebook that supports free GPU to help Machine Learning education more accessible\n",
        "\n",
        "\n",
        " ### PySpark\n",
        " \n",
        " - Spark is written in Scala, but Python is the language for prototyping in Big Data and Machine Learning \n",
        "\n",
        "## This guide will show you how to run PySpark in Google's free Jupiter environment\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qIntq4o9ntL"
      },
      "source": [
        "# **Let's Get Started**:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUq5HMWtVZb5"
      },
      "source": [
        "## Step 1: Install Java 8\n",
        "\n",
        "Use Linux apt-get command-line tool to install OpenJDK 8 (not Oracle Java)\n",
        "\n",
        "http://openjdk.java.net/projects/jdk8/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0ZQ8MJLTgQ4"
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TzfK6c6XlIA"
      },
      "source": [
        "### Step 2: Download Apache Spark \n",
        "\n",
        "Open https://spark.apache.org/downloads.html \n",
        "\n",
        "Go to Archived Releases. Copy the link to spark-2.4.1-bin-hadoop2.7.tgz \n",
        "\n",
        "Use !wget command to download the file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0Q4shslm6OQ"
      },
      "source": [
        "!wget -q https://archive.apache.org/dist/spark/spark-2.4.1/spark-2.4.1-bin-hadoop2.7.tgz"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYvN-Gpxp8Nf"
      },
      "source": [
        "Extract .tar files\n",
        "\n",
        "Use tar command"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcGt8jVbqJ28"
      },
      "source": [
        "!tar xf spark-2.4.1-bin-hadoop2.7.tgz "
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8PWQsrPrqro"
      },
      "source": [
        "### Step 3: Set the environment path \n",
        "\n",
        "Use the os module\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rR4fDX9zruW4"
      },
      "source": [
        "import os"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VPVtxrfslBd"
      },
      "source": [
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.3.2-bin-hadoop2.7\""
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zv5AUhXNssKl"
      },
      "source": [
        "### Step 4: Install findspark so next time you can import pyspark like any other python library\n",
        "\n",
        "Use pip install \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOK5Q5Mvugip"
      },
      "source": [
        "!pip install -q findspark"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ABfWN9luuVI"
      },
      "source": [
        "### Step 5: Test if the installation was successful \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFvQbqxfvP3G"
      },
      "source": [
        "import findspark\n",
        "\n",
        "findspark.init(\"/content/spark-2.4.1-bin-hadoop2.7\")\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-dxI_A8wscz"
      },
      "source": [
        "from pyspark import SparkContext, SparkConf"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-IPCkY7v2y-"
      },
      "source": [
        "from pyspark.sql import SparkSession\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVYMwFZzv6PN"
      },
      "source": [
        "spark = SparkSession.builder.getOrCreate()"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGfhiAEWxR90"
      },
      "source": [
        "### Step 6: Start using PySpark in Google Colab environment:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qb-MdZiPxXeq",
        "outputId": "a5fb3816-90b9-4182-ffac-c842b2f1178c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "df = spark.sql(\"select 'PySpark' as Hello \")\n",
        "df.show()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+\n",
            "|  Hello|\n",
            "+-------+\n",
            "|PySpark|\n",
            "+-------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}